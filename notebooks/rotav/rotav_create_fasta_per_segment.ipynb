{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d2fb7c1-dc6f-4f8b-bbeb-f52033294f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a3995de-1b11-4ac2-ae44-affd8c39f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vicon.dereplication.derep import run_vsearch\n",
    "from vicon.alignment.ref_align import run_viralmsa\n",
    "from vicon.processing.sample_processing import process_all_samples\n",
    "from vicon.visualization.plots import plot_non_gap_counts\n",
    "from vicon.processing.coverage_analysis import abundant_kmers, crop_df, build_coverage_table, top_kmers_df, find_most_frequent_and_calculate_mismatches, get_i_th_kmers, select_best_kmers, count_seq_coverage, find_best_pair_kmer, calculate_kmer_coverage, find_kmer_position\n",
    "from vicon.io.fasta import read_fasta_to_dataframe\n",
    "from vicon.processing.sample_processing import pipeline_results_cleaner\n",
    "from vicon.utils.helpers import count_non_gap_characters_from_dataframe, combine_fasta_files\n",
    "from vicon.visualization.plots import plot_rel_cons\n",
    "from vicon.io.fasta import create_folders_and_save_sequences, read_fasta, remove_first_record, read_fasta_to_dataframe\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2322bf57-e8d5-4842-b34e-83da7e5caf6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/fast/AG_Ohler/ekarimi/projects/vicon/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# Get the base path from the environment variable\n",
    "base_path = os.getenv(\"PROJECTS_PATH\")\n",
    "base_path = f\"{base_path}vicon/\"\n",
    "print(base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ba90261-3fab-4dd9-b535-725e587dde77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing GenBank files...\n",
      "Base output directory: /fast/AG_Ohler/ekarimi/projects/vicon/data/rotav/Human_Rotavirus_A_1/segments\n",
      "\n",
      "Processing segment 1 from Rotavirus A segment 1.gb\n",
      "\n",
      "Processing segment 10 from Rotavirus A segment 10.gb\n",
      "\n",
      "Processing segment 11 from Rotavirus A segment 11.gb\n",
      "\n",
      "Processing segment 2 from Rotavirus A segment 2.gb\n",
      "\n",
      "Processing segment 3 from Rotavirus A segment 3.gb\n",
      "Warning: Could not extract sequence for CM033490.1 in segment 3\n",
      "\n",
      "Processing segment 4 from Rotavirus A segment 4.gb\n",
      "\n",
      "Processing segment 5 from Rotavirus A segment 5.gb\n",
      "\n",
      "Processing segment 6 from Rotavirus A segment 6.gb\n",
      "\n",
      "Processing segment 7 from Rotavirus A segment 7.gb\n",
      "\n",
      "Processing segment 8 from Rotavirus A segment 8.gb\n",
      "\n",
      "Processing segment 9 from Rotavirus A segment 9.gb\n",
      "\n",
      "Processing Summary:\n",
      "--------------------------------------------------\n",
      "Segment 1:\n",
      "  - Processed: 3291\n",
      "  - Successful: 3291\n",
      "  - Failed: 0\n",
      "Segment 2:\n",
      "  - Processed: 3340\n",
      "  - Successful: 3340\n",
      "  - Failed: 0\n",
      "Segment 3:\n",
      "  - Processed: 3348\n",
      "  - Successful: 3347\n",
      "  - Failed: 1\n",
      "Segment 4:\n",
      "  - Processed: 3708\n",
      "  - Successful: 3708\n",
      "  - Failed: 0\n",
      "Segment 5:\n",
      "  - Processed: 200\n",
      "  - Successful: 200\n",
      "  - Failed: 0\n",
      "Segment 6:\n",
      "  - Processed: 4009\n",
      "  - Successful: 4009\n",
      "  - Failed: 0\n",
      "Segment 7:\n",
      "  - Processed: 3606\n",
      "  - Successful: 3606\n",
      "  - Failed: 0\n",
      "Segment 8:\n",
      "  - Processed: 3439\n",
      "  - Successful: 3439\n",
      "  - Failed: 0\n",
      "Segment 9:\n",
      "  - Processed: 5300\n",
      "  - Successful: 5300\n",
      "  - Failed: 0\n",
      "Segment 10:\n",
      "  - Processed: 2200\n",
      "  - Successful: 2200\n",
      "  - Failed: 0\n",
      "Segment 11:\n",
      "  - Processed: 3407\n",
      "  - Successful: 3407\n",
      "  - Failed: 0\n",
      "\n",
      "Created 11 segment directories in /fast/AG_Ohler/ekarimi/projects/vicon/data/rotav/Human_Rotavirus_A_1/segments\n",
      "\n",
      "Files created:\n",
      "segment_1/sequences.fasta: 10479.11 KB\n",
      "segment_2/sequences.fasta: 8772.22 KB\n",
      "segment_3/sequences.fasta: 90371.83 KB\n",
      "segment_4/sequences.fasta: 6140.44 KB\n",
      "segment_5/sequences.fasta: 307.97 KB\n",
      "segment_6/sequences.fasta: 5159.90 KB\n",
      "segment_7/sequences.fasta: 3746.42 KB\n",
      "segment_8/sequences.fasta: 3582.10 KB\n",
      "segment_9/sequences.fasta: 5245.48 KB\n",
      "segment_10/sequences.fasta: 1617.00 KB\n",
      "segment_11/sequences.fasta: 2411.99 KB\n",
      "\n",
      "Total size of all FASTA files: 134.60 MB\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "from Bio import SeqIO\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from Bio import BiopythonWarning\n",
    "\n",
    "# Filter out Biopython warnings\n",
    "warnings.filterwarnings('ignore', category=BiopythonWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "def extract_segment_number(filename):\n",
    "    \"\"\"Extract segment number from filename.\"\"\"\n",
    "    match = re.search(r'segment\\s*(\\d+)', filename, re.IGNORECASE)\n",
    "    return int(match.group(1)) if match else None\n",
    "\n",
    "def parse_collection_date(date_str):\n",
    "    \"\"\"Parse and standardize collection date.\"\"\"\n",
    "    if not date_str:\n",
    "        return \"NA\"\n",
    "    # Remove any text in parentheses\n",
    "    date_str = re.sub(r'\\([^)]*\\)', '', date_str).strip()\n",
    "    return date_str\n",
    "\n",
    "def extract_sequence_from_origin(record):\n",
    "    \"\"\"Extract sequence from ORIGIN section of GenBank record.\"\"\"\n",
    "    if not hasattr(record, '_raw') or not record._raw:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Find ORIGIN section\n",
    "        origin_match = re.search(r'ORIGIN\\s*(.*?)\\/\\/', record._raw, re.DOTALL)\n",
    "        if not origin_match:\n",
    "            return None\n",
    "        \n",
    "        # Extract sequence\n",
    "        origin_text = origin_match.group(1)\n",
    "        # Remove numbers and whitespace, join all lines\n",
    "        sequence = ''.join(re.sub(r'[\\d\\s]', '', line) for line in origin_text.split('\\n'))\n",
    "        return sequence.upper() if sequence else None\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting sequence from ORIGIN for {record.id}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def extract_record_info(record):\n",
    "    \"\"\"Extract required information from a GenBank record.\"\"\"\n",
    "    # Initialize default values\n",
    "    info = {\n",
    "        'accession': 'NA',\n",
    "        'organism': 'NA',\n",
    "        'geo_loc_name': 'NA',\n",
    "        'collection_date': 'NA'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Get accession (without version)\n",
    "        if hasattr(record, 'annotations'):\n",
    "            if 'accessions' in record.annotations and record.annotations['accessions']:\n",
    "                info['accession'] = record.annotations['accessions'][0]\n",
    "            else:\n",
    "                info['accession'] = record.id.split('.')[0]\n",
    "        \n",
    "        # Get organism\n",
    "        if hasattr(record, 'annotations') and 'organism' in record.annotations:\n",
    "            info['organism'] = record.annotations['organism']\n",
    "        \n",
    "        # Extract features from source\n",
    "        for feature in record.features:\n",
    "            if feature.type == 'source':\n",
    "                qualifiers = feature.qualifiers\n",
    "                \n",
    "                # First check for geo_loc_name directly\n",
    "                if 'geo_loc_name' in qualifiers:\n",
    "                    info['geo_loc_name'] = qualifiers['geo_loc_name'][0]\n",
    "                # Fallback to other location fields if geo_loc_name is not present\n",
    "                elif 'country' in qualifiers:\n",
    "                    info['geo_loc_name'] = qualifiers['country'][0]\n",
    "                elif 'isolation_source' in qualifiers:\n",
    "                    info['geo_loc_name'] = qualifiers['isolation_source'][0]\n",
    "                elif 'lat_lon' in qualifiers:\n",
    "                    info['geo_loc_name'] = qualifiers['lat_lon'][0]\n",
    "                elif 'note' in qualifiers and 'location' in qualifiers['note'][0].lower():\n",
    "                    info['geo_loc_name'] = qualifiers['note'][0]\n",
    "                \n",
    "                if 'collection_date' in qualifiers:\n",
    "                    info['collection_date'] = parse_collection_date(qualifiers['collection_date'][0])\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting info for {record.id}: {str(e)}\")\n",
    "    \n",
    "    return info\n",
    "\n",
    "def process_genbank_files(input_dir, base_output_dir):\n",
    "    \"\"\"Process GenBank files and create separate FASTA files for each segment.\"\"\"\n",
    "    # Dictionary to store file handles and statistics\n",
    "    segment_files = {}\n",
    "    stats = defaultdict(lambda: {'processed': 0, 'failed': 0})\n",
    "    \n",
    "    try:\n",
    "        # Process each GenBank file\n",
    "        for gb_file in sorted(Path(input_dir).glob('*.gb')):\n",
    "            segment_num = extract_segment_number(gb_file.name)\n",
    "            if segment_num is None:\n",
    "                print(f\"Warning: Could not extract segment number from {gb_file.name}\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nProcessing segment {segment_num} from {gb_file.name}\")\n",
    "            \n",
    "            # Create segment-specific directory and file\n",
    "            if segment_num not in segment_files:\n",
    "                # Create directory for this segment\n",
    "                segment_dir = os.path.join(base_output_dir, f\"segment_{segment_num}\")\n",
    "                os.makedirs(segment_dir, exist_ok=True)\n",
    "                \n",
    "                # Create file handle in the segment directory\n",
    "                output_file = os.path.join(segment_dir, \"sequences.fasta\")\n",
    "                segment_files[segment_num] = open(output_file, 'w')\n",
    "            \n",
    "            # Parse the GenBank file\n",
    "            for record in SeqIO.parse(gb_file, \"genbank\"):\n",
    "                stats[segment_num]['processed'] += 1\n",
    "                info = extract_record_info(record)\n",
    "                \n",
    "                # Try to get sequence from record.seq first\n",
    "                sequence = None\n",
    "                try:\n",
    "                    sequence = str(record.seq).upper()\n",
    "                except:\n",
    "                    # If that fails, try to extract from ORIGIN section\n",
    "                    sequence = extract_sequence_from_origin(record)\n",
    "                \n",
    "                if not sequence:\n",
    "                    print(f\"Warning: Could not extract sequence for {record.id} in segment {segment_num}\")\n",
    "                    stats[segment_num]['failed'] += 1\n",
    "                    continue\n",
    "                \n",
    "                # Create header\n",
    "                header = f\">{info['accession']}|{segment_num}|{info['organism']}|{info['geo_loc_name']}|{info['collection_date']}\"\n",
    "                \n",
    "                # Write to appropriate segment file\n",
    "                segment_files[segment_num].write(f\"{header}\\n\")\n",
    "                \n",
    "                # Write sequence in lines of 80 characters\n",
    "                for i in range(0, len(sequence), 80):\n",
    "                    segment_files[segment_num].write(sequence[i:i+80] + '\\n')\n",
    "    \n",
    "    finally:\n",
    "        # Close all file handles\n",
    "        for fh in segment_files.values():\n",
    "            fh.close()\n",
    "    \n",
    "    return len(segment_files), stats\n",
    "\n",
    "def main():\n",
    "    # Set input and output paths\n",
    "    input_dir = \"/fast/AG_Ohler/ekarimi/projects/vicon/data/rotav/Human_Rotavirus_A_1\"\n",
    "    # Create a base directory for all segments\n",
    "    base_output_dir = os.path.join(input_dir, \"segments\")\n",
    "    \n",
    "    print(f\"Processing GenBank files...\")\n",
    "    print(f\"Base output directory: {base_output_dir}\")\n",
    "    num_segments, stats = process_genbank_files(input_dir, base_output_dir)\n",
    "    \n",
    "    print(f\"\\nProcessing Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    for segment_num in sorted(stats.keys()):\n",
    "        processed = stats[segment_num]['processed']\n",
    "        failed = stats[segment_num]['failed']\n",
    "        success = processed - failed\n",
    "        print(f\"Segment {segment_num}:\")\n",
    "        print(f\"  - Processed: {processed}\")\n",
    "        print(f\"  - Successful: {success}\")\n",
    "        print(f\"  - Failed: {failed}\")\n",
    "    \n",
    "    print(f\"\\nCreated {num_segments} segment directories in {base_output_dir}\")\n",
    "    print(\"\\nFiles created:\")\n",
    "    total_size = 0\n",
    "    for i in range(1, 12):\n",
    "        segment_dir = os.path.join(base_output_dir, f\"segment_{i}\")\n",
    "        fasta_file = os.path.join(segment_dir, \"sequences.fasta\")\n",
    "        if os.path.exists(fasta_file):\n",
    "            size = os.path.getsize(fasta_file)\n",
    "            total_size += size\n",
    "            print(f\"segment_{i}/sequences.fasta: {size/1024:.2f} KB\")\n",
    "    print(f\"\\nTotal size of all FASTA files: {total_size/1024/1024:.2f} MB\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626f8338-1ab3-4c57-ad5b-a6fa333aed35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd9adf-c705-490b-aada-2f2d3f9f31ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c5c4c-fd89-4974-82d5-e8cd935deb25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6862117c-33f6-4045-a089-081705fbca0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf805f6-ace5-48cb-b39a-57811c27dc52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaae1ff-31d8-4650-aa47-13963ac228b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vicon]",
   "language": "python",
   "name": "conda-env-vicon-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
